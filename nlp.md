# NLP

Natural Language Processing

What will we talk in this course:

- **Basic Text Processing**: regular expressions, tokenization, normalization, lemmatization, stemming, segmentation.

- **Language Models**: n-grams.

- **Text Classification**: bag-of-words,n-grams, feature engineering, genrative and discriminative classifiers.

- **Vectorized representation of words**: lexical semantics, word embeddings.

- **Sequence Models**: hidden Markov models, conditional random fields, POS-tagging and named entity recognition.

- **Neral networks in NLP**: neural language models, RNN (Recurrent Neural Network)

- **Transformers**

- **Large Language Models**

# NlP Tasks

## Tokenization

Split a sentence into tokens.


## Sentence Breaking

Split a text into sentences

## Part-of-Speech (POS) tagging


Determine the role category for each word in a sentence


## Syntax Parsing

Determining the parse tree of a sentence. This stems from grammatical analysis and is a hard problem because of ambiguity

## Word Sense Disambiguation

select the meaning of words in a context. There are words that are homonyms and can only be differentiated by the context.



## Name Entity Recognition

Determine which items in a text map to entities-> People institutions places, dates, concepts.

## Co-reference resolution

Determine which words mention/refer to the same objects (entities)

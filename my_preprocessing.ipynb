{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Processing With NLTK\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import regexp_tokenize,word_tokenize\n",
    "# nltk.download('punkt')\n",
    "print(\"Text Processing With NLTK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {\n",
    "    \"simple_Text\": \"The brown fox jumps over the lazy dog\",\n",
    "    \"punctuation\": \"Hello. Who am I speaking with? Dear Lord!\",\n",
    "    \"contractions\": \"I'am am the one who knocks. Yes you're it, it's obvious\",\n",
    "    \"numbers\": \"12.30$ 77.5% 499.99â‚¬ 0,77%\",\n",
    "    \"compound_words\": \"guarda-chuva, nao-sei-mais\",\n",
    "    \"abreviaturas\": \"U.S.A.\"\n",
    "}\n",
    "corpus_tokens = {\n",
    "    'simple_Text': ['The', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog'],\n",
    "    'punctuation': ['Hello', '.', 'Who', 'am', 'I', 'speaking', 'with', '?', 'Dear', 'Lord', '!'],\n",
    "    'contractions': [\"I'am\", 'am', 'the', 'one', 'who', 'knocks', '.', 'Yes', \"you're\", 'it', ',', \"it's\", 'obvious'],\n",
    "    'numbers': ['12.30$', '77.5%', '499.99â‚¬', '0,77%'],\n",
    "    'compound_words': ['guarda-chuva', ',', 'nao-sei-mais'],\n",
    "    'abreviaturas': ['U.S.A.'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tests(tests):\n",
    "    passed = {name: test for name, test in tests.items() if test[\"passed\"]}\n",
    "    failed = {name: test for name, test in tests.items() if not test[\"passed\"]}\n",
    "\n",
    "    for key, test in passed.items():\n",
    "        print(f\"âœ… {key}\")\n",
    "        print(f\"      Output: {test['result']}\")\n",
    "\n",
    "    for key, test in failed.items():\n",
    "        print(f\"ðŸš¨ {key}\")\n",
    "        print(f\"     Expected: {test['expected']}\")\n",
    "        print(f\"     Got     : {test['result']}\")\n",
    "\n",
    "\n",
    "def test_tokenize(tokenizer):\n",
    "    tests = {}\n",
    "    for test, text in corpus.items():\n",
    "        got = tokenizer(text)\n",
    "        expected = corpus_tokens[test]\n",
    "        tests[test] = {\n",
    "            \"result\": got,\n",
    "            \"expected\": expected,\n",
    "            \"passed\": got == expected\n",
    "        }\n",
    "    print_tests(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… simple_Text\n",
      "      Output: ['The', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
      "âœ… punctuation\n",
      "      Output: ['Hello', '.', 'Who', 'am', 'I', 'speaking', 'with', '?', 'Dear', 'Lord', '!']\n",
      "âœ… contractions\n",
      "      Output: [\"I'am\", 'am', 'the', 'one', 'who', 'knocks', '.', 'Yes', \"you're\", 'it', ',', \"it's\", 'obvious']\n",
      "âœ… numbers\n",
      "      Output: ['12.30$', '77.5%', '499.99â‚¬', '0,77%']\n",
      "âœ… compound_words\n",
      "      Output: ['guarda-chuva', ',', 'nao-sei-mais']\n",
      "âœ… abreviaturas\n",
      "      Output: ['U.S.A.']\n"
     ]
    }
   ],
   "source": [
    "pattern = r'''(?x)\n",
    "    (?:[a-zA-Z]\\.)+    # Abreviaturas\n",
    "    | (?:\\w+)'(?:am|re|s|t)\n",
    "    | (?:\\w+(?:-\\w+)+) # Compound words\n",
    "    | \\d+(?:[.,]\\d+)?[$Â£%â‚¬]? # Numbers and currencies\n",
    "    | \\w+              # Normal words\n",
    "    | [.,:-?!]         # Punctuation\n",
    "    '''\n",
    "\n",
    "test_tokenize(lambda text : regexp_tokenize(text,pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
